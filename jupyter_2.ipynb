{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:23:09.991086: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 01:23:10.049479: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 01:23:10.050409: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 01:23:10.930111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>14.65</td>\n",
       "      <td>15.24</td>\n",
       "      <td>14.61</td>\n",
       "      <td>15.20</td>\n",
       "      <td>13.524044</td>\n",
       "      <td>15223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>15.24</td>\n",
       "      <td>15.27</td>\n",
       "      <td>14.74</td>\n",
       "      <td>15.00</td>\n",
       "      <td>13.346094</td>\n",
       "      <td>15155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15.03</td>\n",
       "      <td>15.05</td>\n",
       "      <td>14.79</td>\n",
       "      <td>15.03</td>\n",
       "      <td>13.372787</td>\n",
       "      <td>8936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>14.99</td>\n",
       "      <td>15.00</td>\n",
       "      <td>14.87</td>\n",
       "      <td>14.95</td>\n",
       "      <td>13.301606</td>\n",
       "      <td>6515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.64</td>\n",
       "      <td>14.74</td>\n",
       "      <td>13.114761</td>\n",
       "      <td>8362600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close  Adj Close    Volume\n",
       "Date                                                       \n",
       "2018-01-02  14.65  15.24  14.61  15.20  13.524044  15223200\n",
       "2018-01-03  15.24  15.27  14.74  15.00  13.346094  15155900\n",
       "2018-01-04  15.03  15.05  14.79  15.03  13.372787   8936100\n",
       "2018-01-05  14.99  15.00  14.87  14.95  13.301606   6515600\n",
       "2018-01-08  14.88  14.95  14.64  14.74  13.114761   8362600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = yf.download(\"Gold\", start=\"2018-01-01\", end=\"2022-01-01\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>14.650000</td>\n",
       "      <td>15.240000</td>\n",
       "      <td>14.610000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>15223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>15.240000</td>\n",
       "      <td>15.270000</td>\n",
       "      <td>14.740000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15.030000</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>14.790000</td>\n",
       "      <td>15.030000</td>\n",
       "      <td>8936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>14.990000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.870000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>6515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>14.880000</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>14.640000</td>\n",
       "      <td>14.740000</td>\n",
       "      <td>8362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>18.410000</td>\n",
       "      <td>11740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>18.450001</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>18.370001</td>\n",
       "      <td>10310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.660000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>17290100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.889999</td>\n",
       "      <td>18.389999</td>\n",
       "      <td>18.820000</td>\n",
       "      <td>13570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>18.980000</td>\n",
       "      <td>19.080000</td>\n",
       "      <td>18.780001</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14284100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close    Volume\n",
       "Date                                                            \n",
       "2018-01-02  14.650000  15.240000  14.610000  15.200000  15223200\n",
       "2018-01-03  15.240000  15.270000  14.740000  15.000000  15155900\n",
       "2018-01-04  15.030000  15.050000  14.790000  15.030000   8936100\n",
       "2018-01-05  14.990000  15.000000  14.870000  14.950000   6515600\n",
       "2018-01-08  14.880000  14.950000  14.640000  14.740000   8362600\n",
       "...               ...        ...        ...        ...       ...\n",
       "2021-12-27  18.500000  18.580000  18.270000  18.410000  11740600\n",
       "2021-12-28  18.450001  18.670000  18.309999  18.370001  10310100\n",
       "2021-12-29  18.240000  18.660000  18.219999  18.400000  17290100\n",
       "2021-12-30  18.400000  18.889999  18.389999  18.820000  13570900\n",
       "2021-12-31  18.980000  19.080000  18.780001  19.000000  14284100\n",
       "\n",
       "[1008 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=[\"Adj Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"High\"]\n",
    "target = target.to_numpy()\n",
    "data.drop(columns=\"High\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_data = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "data = scaler_data.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=[\"date\", \"open\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "target = scaler_target.fit_transform(target.reshape(-1, 1))\n",
    "target = pd.DataFrame(target, columns=[\"max\"])\n",
    "\n",
    "data.drop(columns=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler_data.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_data, f)\n",
    "\n",
    "with open('scaler_target.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.618247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.612653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.653680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.663005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max\n",
       "0 -0.618247\n",
       "1 -0.612653\n",
       "2 -0.653680\n",
       "3 -0.663005\n",
       "4 -0.672329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, target, lookback):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data) - lookback):\n",
    "        x.append(data[i:i+lookback])\n",
    "        y.append(target[i+lookback])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "lookback = 7\n",
    "x, y = prepare_data(data.values, target.values, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:23:12.488102: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-19 01:23:12.753959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:23:12.756530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:23:12.758353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(lookback, x_train.shape[2])),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:23:13.166692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:23:13.169147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:23:13.170776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-19 01:23:13.765966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:23:13.768365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:23:13.770062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 [===========================>..] - ETA: 0s - loss: 0.1317 - mse: 0.1317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:23:15.066962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:23:15.068859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:23:15.070256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.02361, saving model to model.h5\n",
      "50/50 [==============================] - 2s 15ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 2/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 2: val_loss improved from 0.02361 to 0.01786, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 3/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0144 - mse: 0.0144\n",
      "Epoch 3: val_loss improved from 0.01786 to 0.01531, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 4/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0129 - mse: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01531 to 0.01465, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 5/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01465 to 0.01377, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 6/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0111 - mse: 0.0111\n",
      "Epoch 6: val_loss improved from 0.01377 to 0.01347, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 7/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 7: val_loss improved from 0.01347 to 0.01239, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 8/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 8: val_loss improved from 0.01239 to 0.01144, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 9/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 9: val_loss did not improve from 0.01144\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 10/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 10: val_loss improved from 0.01144 to 0.01034, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 11/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 11: val_loss improved from 0.01034 to 0.00997, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 12/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 12: val_loss improved from 0.00997 to 0.00903, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 13/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 13: val_loss did not improve from 0.00903\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 14/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 14: val_loss improved from 0.00903 to 0.00893, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 15/64\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 15: val_loss improved from 0.00893 to 0.00887, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 16/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 16: val_loss did not improve from 0.00887\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 17/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 17: val_loss did not improve from 0.00887\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 18/64\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 18: val_loss did not improve from 0.00887\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 19/64\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 19: val_loss improved from 0.00887 to 0.00876, saving model to model.h5\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 20/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 20: val_loss improved from 0.00876 to 0.00834, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 21/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 21: val_loss did not improve from 0.00834\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 22/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 22: val_loss did not improve from 0.00834\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 23/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 23: val_loss improved from 0.00834 to 0.00772, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 24/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 24: val_loss did not improve from 0.00772\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 25/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 25: val_loss improved from 0.00772 to 0.00759, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 26/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 26: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 27/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 27: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 28/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 28: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 29/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 29: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 30/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 30: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 31/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 31: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 32/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 32: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 33/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 33: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 34/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 34: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 35/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 35: val_loss did not improve from 0.00759\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 36/64\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 36: val_loss improved from 0.00759 to 0.00734, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 37/64\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 37: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 38/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 38: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 39/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 39: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 40/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 40: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 41/64\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 41: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 42/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 42: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 43/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 43: val_loss did not improve from 0.00734\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 44/64\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 44: val_loss improved from 0.00734 to 0.00725, saving model to model.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 45/64\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 45: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 46/64\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 46: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 47/64\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 47: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 48/64\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 48: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 49/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 49: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 50/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 50: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 51/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 51: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 52/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 52: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 53/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 53: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 54/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 54: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 55/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 55: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 56/64\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 56: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 57/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 57: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 58/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 58: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 59/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 59: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 60/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 60: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 61/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 61: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 62/64\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 62: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0078 - val_mse: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/64\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 63: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 64/64\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 64: val_loss did not improve from 0.00725\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0075 - val_mse: 0.0075\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=64, batch_size=16, validation_data=(x_test, y_test), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0074523077346384525, 0.0074523077346384525]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 396ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:23:33.912826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:23:33.914947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:23:33.916417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test[85].reshape(1, x_test[0].shape[0], x_test[0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler_target.pkl', 'rb') as f:\n",
    "    scaler_target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.803875]]\n"
     ]
    }
   ],
   "source": [
    "result = scaler_target.inverse_transform(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.97999954]]\n"
     ]
    }
   ],
   "source": [
    "answer = scaler_target.inverse_transform(y_test[85].reshape(1, y_test[0].shape[0]))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 01:24:13.587651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-19 01:24:13.589894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-19 01:24:13.591475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
